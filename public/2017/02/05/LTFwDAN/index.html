<!DOCTYPE html>
<html>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="“It’s a good habite to take notes”  前言You can find the related paper from the following address. Learning Transferable Features with Deep Adaptation Networks(1) How transferable are features in deep">
<meta name="keywords" content="Notes">
<meta property="og:type" content="article">
<meta property="og:title" content="Learning Transferanle Features with Deep Adapation Networks">
<meta property="og:url" content="http://miyunluo.com/2017/02/05/LTFwDAN/index.html">
<meta property="og:site_name" content="miyunLuo">
<meta property="og:description" content="“It’s a good habite to take notes”  前言You can find the related paper from the following address. Learning Transferable Features with Deep Adaptation Networks(1) How transferable are features in deep">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://miyunluo.com/images/in-post/post-blog-DANmdoel.png">
<meta property="og:updated_time" content="2018-04-23T12:03:10.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Learning Transferanle Features with Deep Adapation Networks">
<meta name="twitter:description" content="“It’s a good habite to take notes”  前言You can find the related paper from the following address. Learning Transferable Features with Deep Adaptation Networks(1) How transferable are features in deep">
<meta name="twitter:image" content="http://miyunluo.com/images/in-post/post-blog-DANmdoel.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-200x200.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Learning Transferanle Features with Deep Adapation Networks</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/research/">Research</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2017/07/24/merlionRes/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2017/02/01/UDAbB/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://miyunluo.com/2017/02/05/LTFwDAN/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://miyunluo.com/2017/02/05/LTFwDAN/&text=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://miyunluo.com/2017/02/05/LTFwDAN/&is_video=false&description=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Learning Transferanle Features with Deep Adapation Networks&body=Check out this article: http://miyunluo.com/2017/02/05/LTFwDAN/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://miyunluo.com/2017/02/05/LTFwDAN/&name=Learning Transferanle Features with Deep Adapation Networks&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正文"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RKHS"><span class="toc-number">2.1.</span> <span class="toc-text">RKHS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MMD"><span class="toc-number">2.2.</span> <span class="toc-text">MMD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MK-MMD"><span class="toc-number">2.3.</span> <span class="toc-text">MK-MMD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-DAN"><span class="toc-number">2.4.</span> <span class="toc-text">Model(DAN)</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index my4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Learning Transferanle Features with Deep Adapation Networks
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">miyunLuo</span>
      </span>
      
    <div class="postdate">
        <time datetime="2017-02-04T16:00:00.000Z" itemprop="datePublished">2017-02-05</time>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Notes/">Notes</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <blockquote>
<p>“It’s a good habite to take notes”</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>You can find the related paper from the following address.</p>
<p><a href="http://jmlr.org/proceedings/papers/v37/long15.pdf" target="_blank" rel="noopener">Learning Transferable Features with Deep Adaptation Networks</a>(1)</p>
<p><a href="http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf" target="_blank" rel="noopener">How transferable are features in deep neural networks?</a>(2)</p>
<p><a href="http://jmlr.org/papers/volume13/gretton12a/gretton12a.pdf" target="_blank" rel="noopener">A Kernel Two-Sample Test</a>(3)</p>
<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Deep neutral network can learn transferable transferable features which generalize well to novel tasks for domain adaptation.(1)</p>
<p>The usual transfer learning approach is to train a base network and then copy its first n layers to the first n layers of a target network. The remaining layers of the target network are then randomly initialized toword the target task. (2)</p>
<p>Here comes some related terms.</p>
<h3 id="RKHS"><a href="#RKHS" class="headerlink" title="RKHS"></a>RKHS</h3><p>RHKS means reproducing kernel Hilbert space.(再生核希尔伯特空间)</p>
<p>First Hilbert space, it is a generalization of Euclidean space. Beginning with the basic vector space, define an  inner product operation in this vector space, the space will be upgraded to an inner product space. The norm is defined:</p>
<p>\begin{aligned} |x|^2=\langle x, x\rangle \end{aligned}</p>
<p>So, it becomes an normed vector space. Norms can define a metric:</p>
<p>\begin{aligned} d(x_1,x_2) = |x_1-x_2| \end{aligned}</p>
<p>Then it becomes a metic space. If it is complete under this metric, the space is called Hilbert Space. In brief, Hilbert space is a complete inner product space.</p>
<p>Then retroducing kernel.</p>
<p>Remember in SVM, when the dataset is not linearly separable, we map the data point to a higher dimesional space and the data may become linearly separable. This higer dimentional space is called “reproducing kernel Hilbert space”. However, it is usually hard to figure out the mapping function because the growth of dimentional number is explosive. Here we need <strong>Kernel Function</strong> to handel this problem. It calculates inner product of two vectors in RKHS. </p>
<p>One useful property is that the same demensional space is isomorphic to each other, which means the inner product, norm, metric and vector operations, etc. can be maintained in the conversion between different space.</p>
<h3 id="MMD"><a href="#MMD" class="headerlink" title="MMD"></a>MMD</h3><p>MMD means maximum mean discrepancy.(最大平均差异) It is used to determine whether the two distributions <strong>p</strong> and <strong>q</strong> are the same. For all the function f whose input is the sample space complying with the certain distribution, if the mean value is same, we assume those two distritions are the same.</p>
<p>Or rather, by finding a continuous function f in the sample space, we get two mean value with different distribution. Then we get <strong>mean discrepancy</strong> by subtracting. Find a f to maximum the mean discrepancy and we get MMD.</p>
<p>For a two-sample test, there are two hypotheses. Null hypothesis: p = q. The alternative hypothesis: p != q.</p>
<p>In RKHS, we have:(3)</p>
<p>\begin{aligned} MMD^2[f,p,q]=|\mu_{p}-\mu_{q}|^2_{H} \end{aligned}</p>
<h3 id="MK-MMD"><a href="#MK-MMD" class="headerlink" title="MK-MMD"></a>MK-MMD</h3><p>MK-MMD means multiple kernel variant of MMD and it minimize Type two error.</p>
<ul>
<li>Type one error: 存伪</li>
<li>Type two error: 弃真</li>
</ul>
<hr>
<h3 id="Model-DAN"><a href="#Model-DAN" class="headerlink" title="Model(DAN)"></a>Model(DAN)</h3><p><img src="/images/in-post/post-blog-DANmdoel.png" alt="img"></p>
<p>The basic architecture is <strong>AlexNet</strong>, which is comprised of five convolutional layers (conv1-conv5) and three fully connected layers (fc6-fc8). The output layer is softmax.</p>
<p>Because features in lower convolutional layers are general, the author starts with an AlexNet model pertained on ImageNet 2012 and copies conv1-conv3 from pertained model, then fine-tunes conv4-conv5 and fully connected layers fc6-fc7, and trains classifier layer fc8, both via backpropagation.</p>
<p>The author adds an MK-MMD-based multi-layer adaptation regularizer to CNN risk so that the distributions on the source and target become similar under the hidden representations of fully connected layers fc6-fc8.</p>

  </div>
</article>



    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/research/">Research</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正文"><span class="toc-number">2.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RKHS"><span class="toc-number">2.1.</span> <span class="toc-text">RKHS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MMD"><span class="toc-number">2.2.</span> <span class="toc-text">MMD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MK-MMD"><span class="toc-number">2.3.</span> <span class="toc-text">MK-MMD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-DAN"><span class="toc-number">2.4.</span> <span class="toc-text">Model(DAN)</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://miyunluo.com/2017/02/05/LTFwDAN/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://miyunluo.com/2017/02/05/LTFwDAN/&text=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://miyunluo.com/2017/02/05/LTFwDAN/&is_video=false&description=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Learning Transferanle Features with Deep Adapation Networks&body=Check out this article: http://miyunluo.com/2017/02/05/LTFwDAN/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://miyunluo.com/2017/02/05/LTFwDAN/&title=Learning Transferanle Features with Deep Adapation Networks"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://miyunluo.com/2017/02/05/LTFwDAN/&name=Learning Transferanle Features with Deep Adapation Networks&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2018 Yudong Luo
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/research/">Research</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

</body>
</html>
<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-102635433-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<!-- Mathjax -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


